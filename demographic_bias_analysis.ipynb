{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8116c5fb-065c-4c4b-adf7-081014417f03",
   "metadata": {},
   "source": [
    "Motivation: Why Demographic Analysis Matters\n",
    "\n",
    "Explanation:\n",
    "This notebook analyzes the demographic composition of the CLIPScore-Light dataset to identify potential representation biases related to gender, age, and skin tone. Such biases can directly affect the fairness and robustness of vision‚Äìlanguage models trained on web-scale data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e0d1b1-1d26-4f3b-91ff-655f5044ee73",
   "metadata": {},
   "source": [
    "Environment Setup and Configuration\n",
    "\n",
    "Explanation:\n",
    "Load required libraries and define paths for the CLIPScore-Light dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01d0637-8df7-46ec-8b2a-d56ae75fc8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bba8781-3f6d-4425-bacb-0690b374c5ac",
   "metadata": {},
   "source": [
    "Config paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71beca6e-3a68-41b6-8cfb-24b650374b7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IN_CSV = \"data/laion_big_light_tau1_0.2989.csv\"\n",
    "OUT_CSV = \"data/laion_big_light_with_demographics.csv\"\n",
    "SUMMARY_JSON = \"data/week5_demographics_summary.json\"\n",
    "\n",
    "CHECKPOINT_EVERY = 200\n",
    "RESUME = True\n",
    "\n",
    "ACTIONS = [\"gender\", \"age\", \"race\"]\n",
    "ENFORCE_DETECTION = False  # important to not crash when no face\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e9799-85a4-4492-a3fb-e15c4d3b55a5",
   "metadata": {},
   "source": [
    "Load CSV + init columns + resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad76cf-bfcf-4240-b121-124928c00f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_path = Path(IN_CSV)\n",
    "out_path = Path(OUT_CSV)\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if RESUME and out_path.exists():\n",
    "    print(\"üîÅ Resuming from:\", out_path)\n",
    "    df = pd.read_csv(out_path)\n",
    "else:\n",
    "    df = pd.read_csv(in_path)\n",
    "\n",
    "for col in [\"face_detected\", \"gender\", \"age\", \"race\"]:\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f07b8f3-626a-46d6-afa0-42672b5d3fe5",
   "metadata": {},
   "source": [
    "Verify image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b2c52-bc76-4b74-ab03-c315d5ab0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert \"image_path\" in df.columns, \"CSV must contain image_path column\"\n",
    "\n",
    "exists_rate = df[\"image_path\"].apply(lambda p: isinstance(p, str) and os.path.exists(p)).mean() * 100\n",
    "print(f\"Exists rate: {exists_rate:.2f}%\")\n",
    "\n",
    "# show one image\n",
    "from PIL import Image\n",
    "sample_path = df.loc[df[\"image_path\"].apply(lambda p: isinstance(p, str) and os.path.exists(p)), \"image_path\"].iloc[0]\n",
    "Image.open(sample_path).convert(\"RGB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd653101-3040-49a6-9bc0-0874d6eafe96",
   "metadata": {},
   "source": [
    "Install/Import DeepFace fix (tf-keras)\n",
    "\n",
    "Run this once if you had the error ‚Äúrequires tf-keras‚Äù."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e450361-1a53-4571-b802-881f716370a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (2.20.1)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.33.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.5)\n",
      "Requirement already satisfied: setuptools in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.2.6)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2025.11.12)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.10.1)\n",
      "Requirement already satisfied: pillow in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (10.2.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.5)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.46.3)\n",
      "Requirement already satisfied: rich in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (14.3.1)\n",
      "Requirement already satisfied: namex in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.18.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\debiasing-and-improving-the-robustness-of-clip-like-models\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U tf-keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b4cf39-cc58-4ccb-9c8b-6a5c91e57c7c",
   "metadata": {},
   "source": [
    "Import DeepFace (after tf-keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4156bc10-17d5-4b31-8593-485ebe49220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Debiasing-and-Improving-the-Robustness-of-CLIP-like-Models\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6226f0-acac-43fa-a3cd-c49d80c471c5",
   "metadata": {},
   "source": [
    "Safe analyze wrapper (anti-crash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f5c6c30-cdba-44b1-949d-a4fd379b1124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_analyze(img_path: str):\n",
    "    try:\n",
    "        res = DeepFace.analyze(\n",
    "            img_path=img_path,\n",
    "            actions=ACTIONS,\n",
    "            enforce_detection=ENFORCE_DETECTION,\n",
    "        )\n",
    "\n",
    "        if isinstance(res, list):\n",
    "            res = res[0] if len(res) > 0 else {}\n",
    "\n",
    "        gender = res.get(\"dominant_gender\")\n",
    "        age = res.get(\"age\")\n",
    "        race = res.get(\"dominant_race\")\n",
    "\n",
    "        face_detected = (gender is not None) or (age is not None) or (race is not None)\n",
    "\n",
    "        return {\n",
    "            \"face_detected\": bool(face_detected),\n",
    "            \"gender\": gender,\n",
    "            \"age\": age,\n",
    "            \"race\": race,\n",
    "        }\n",
    "\n",
    "    except Exception:\n",
    "        return {\n",
    "            \"face_detected\": False,\n",
    "            \"gender\": None,\n",
    "            \"age\": None,\n",
    "            \"race\": None,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced4cb0a-c741-4e2f-93cf-bfa2c01c0565",
   "metadata": {},
   "source": [
    "Determine remaining rows to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab065ca9-b391-4c2d-9472-169fdfa7df41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining rows: 104251\n"
     ]
    }
   ],
   "source": [
    "need_mask = df[\"gender\"].isna() & df[\"age\"].isna() & df[\"race\"].isna()\n",
    "to_process = df.index[need_mask].tolist()\n",
    "print(\"Remaining rows:\", len(to_process))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1783e3-7c7a-4abc-a3c4-9da9a2eb6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DEBUG = 10_000   # change √† 2000 / 5000 / 10000 pour tester\n",
    "\n",
    "to_process = to_process[:min(N_DEBUG, len(to_process))]\n",
    "print(\"Now processing only:\", len(to_process), \"rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217a5bc-ec8a-47db-8f58-f4a4896c8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 2000           # traite 2000 images puis sauvegarde\n",
    "CHECKPOINT_EVERY = 200      # checkpoint pendant le chunk\n",
    "\n",
    "processed_total = 0\n",
    "t0 = time.time()\n",
    "\n",
    "# recompute remaining each time (useful when you restart kernel)\n",
    "need_mask = df[\"gender\"].isna() & df[\"age\"].isna() & df[\"race\"].isna()\n",
    "remaining = df.index[need_mask].tolist()\n",
    "print(\"Remaining rows:\", len(remaining))\n",
    "\n",
    "chunk_id = 0\n",
    "\n",
    "while len(remaining) > 0:\n",
    "    chunk_id += 1\n",
    "    chunk_idx = remaining[:min(CHUNK_SIZE, len(remaining))]\n",
    "    print(f\"\\nüöÄ Chunk {chunk_id} ‚Äî processing {len(chunk_idx)} rows\")\n",
    "\n",
    "    processed_chunk = 0\n",
    "\n",
    "    for idx in tqdm(chunk_idx, desc=f\"Chunk {chunk_id}\"):\n",
    "        img_path = df.at[idx, \"image_path\"]\n",
    "\n",
    "        if not isinstance(img_path, str) or not os.path.exists(img_path):\n",
    "            df.at[idx, \"face_detected\"] = False\n",
    "            df.at[idx, \"gender\"] = pd.NA\n",
    "            df.at[idx, \"age\"] = pd.NA\n",
    "            df.at[idx, \"race\"] = pd.NA\n",
    "        else:\n",
    "            out = safe_analyze(img_path)\n",
    "            df.at[idx, \"face_detected\"] = out[\"face_detected\"]\n",
    "            df.at[idx, \"gender\"] = out[\"gender\"]\n",
    "            df.at[idx, \"age\"] = out[\"age\"]\n",
    "            df.at[idx, \"race\"] = out[\"race\"]\n",
    "\n",
    "        processed_chunk += 1\n",
    "        processed_total += 1\n",
    "\n",
    "        # checkpoint intra-chunk\n",
    "        if processed_chunk % CHECKPOINT_EVERY == 0:\n",
    "            df.to_csv(out_path, index=False)\n",
    "            elapsed = (time.time() - t0) / 60\n",
    "            print(f\"üíæ Checkpoint saved ‚Äî total processed: {processed_total} ‚Äî {elapsed:.1f} min\")\n",
    "\n",
    "    # fin du chunk => save obligatoire\n",
    "    df.to_csv(out_path, index=False)\n",
    "    elapsed = (time.time() - t0) / 60\n",
    "    print(f\"‚úÖ Chunk {chunk_id} saved ‚Äî total processed: {processed_total} ‚Äî {elapsed:.1f} min\")\n",
    "\n",
    "    # recompute remaining\n",
    "    need_mask = df[\"gender\"].isna() & df[\"age\"].isna() & df[\"race\"].isna()\n",
    "    remaining = df.index[need_mask].tolist()\n",
    "\n",
    "print(\"\\nüéâ Done! Final saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed0b820-7736-4aaa-9131-76450e6bd07f",
   "metadata": {},
   "source": [
    "Run inference with checkpoint + resume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f2290b-8a43-4b17-b0e9-0a6cb7164e29",
   "metadata": {},
   "source": [
    "Basic stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3b8938f-4044-4e88-b2b2-f085f9b62ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"face_detected\"].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8451aaf-7d72-4a43-9aad-83b0cd95b53c",
   "metadata": {},
   "source": [
    "Plots (Gender / Age / Race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d834664a-a7f1-4517-95e3-f54c29fbe845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender\n",
    "g = df[\"gender\"].dropna()\n",
    "if len(g) > 0:\n",
    "    g.value_counts().plot(kind=\"bar\", title=\"Gender distribution\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No gender predictions available\")\n",
    "\n",
    "# Age\n",
    "a = df[\"age\"].dropna()\n",
    "if len(a) > 0:\n",
    "    a.plot(kind=\"hist\", bins=30, title=\"Age distribution\")\n",
    "    plt.xlabel(\"Age\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No age predictions available\")\n",
    "\n",
    "# Race\n",
    "r = df[\"race\"].dropna()\n",
    "if len(r) > 0:\n",
    "    r.value_counts().plot(kind=\"bar\", title=\"Race distribution\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No race predictions available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa88974-cbe7-4996-a2a8-786efeae3533",
   "metadata": {},
   "source": [
    "JSON summary (for report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115702c8-3a43-46f1-8bcc-9ff28a9c6660",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"input_csv\": IN_CSV,\n",
    "    \"rows\": int(len(df)),\n",
    "    \"exists_rate\": float(df[\"image_path\"].apply(lambda p: isinstance(p, str) and os.path.exists(p)).mean()),\n",
    "    \"face_detected_rate\": float(df[\"face_detected\"].fillna(False).astype(bool).mean()),\n",
    "    \"gender_non_null\": int(df[\"gender\"].notna().sum()),\n",
    "    \"age_non_null\": int(df[\"age\"].notna().sum()),\n",
    "    \"race_non_null\": int(df[\"race\"].notna().sum()),\n",
    "}\n",
    "\n",
    "Path(SUMMARY_JSON).parent.mkdir(parents=True, exist_ok=True)\n",
    "Path(SUMMARY_JSON).write_text(json.dumps(summary, indent=2), encoding=\"utf-8\")\n",
    "summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
